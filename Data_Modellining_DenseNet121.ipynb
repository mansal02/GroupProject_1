{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb412370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras    \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab9ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2802 images belonging to 10 classes.\n",
      "Found 1069 images belonging to 10 classes.\n",
      "Found 1083 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = './dataset/train'\n",
    "valid_path = './dataset/val'\n",
    "test_path = './dataset/test'\n",
    "\n",
    "breeds = [\n",
    "    \"Holstein_cow\", \"Jersey_cow\", \"Angus_cow\", \"Brahman_cow\", \"Hereford_cow\",\n",
    "    \"Simmental_cow\", \"Limousin_cow\", \"Guernsey_cow\", \"Charolais_cow\", \"Ayrshire_cow\"\n",
    "]\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "                .flow_from_directory(directory=train_path, target_size=(224,224), classes=breeds, batch_size = 10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "                .flow_from_directory(directory=valid_path, target_size=(224,224), classes=breeds, batch_size = 10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "                .flow_from_directory(directory=test_path, target_size=(224,224), classes=breeds, batch_size = 10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b81f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image batch:  (10, 224, 224, 3)\n",
      "Shape of the label batch:  (10, 10)\n"
     ]
    }
   ],
   "source": [
    "assert train_batches.n >= 1000\n",
    "assert valid_batches.n >= 300\n",
    "assert test_batches.n >= 150\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 10\n",
    "assert train_batches.batch_size == valid_batches.batch_size == test_batches.batch_size == 10\n",
    "assert train_batches.class_indices == valid_batches.class_indices == test_batches.class_indices\n",
    "\n",
    "imgs , labels = next(train_batches)\n",
    "print(\"Shape of the image batch: \", imgs.shape)\n",
    "print(\"Shape of the label batch: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cf9456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize = (20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr,axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2e4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=(3,3),activation='relu', padding='same',input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Conv2D(filters=64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41b4f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "import time\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, MobileNetV3Large\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32cf5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model_class, input_shape, num_classes):\n",
    "    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    optimizer = Adam(learning_rate=0.001)  \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Helper function to calculate mAP\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    # y_true and y_pred should be numpy arrays\n",
    "    # This is a simple implementation for multiclass, multi-label\n",
    "    import sklearn.metrics\n",
    "    return sklearn.metrics.average_precision_score(y_true, y_pred, average='macro')\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(breeds)\n",
    "epochs = 50\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f0481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DenseNet121...\n",
      "Epoch 1/50\n",
      " 28/281 [=>............................] - ETA: 30:17:58 - loss: 2.5399 - accuracy: 0.2036"
     ]
    }
   ],
   "source": [
    "print(\"Training DenseNet121...\")\n",
    "densenet121_model = build_model(DenseNet121, input_shape, num_classes)\n",
    "start_time = time.time()\n",
    "history = densenet121_model.fit(\n",
    "    train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    ")\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs, val_labels = next(valid_batches)\n",
    "val_preds = densenet121_model.predict(val_imgs)\n",
    "acc = np.mean(np.argmax(val_preds, axis=1) == np.argmax(val_labels, axis=1))\n",
    "mAP = mean_average_precision(val_labels, val_preds)\n",
    "results['DenseNet121'] = {\n",
    "    'training_time_sec': training_time,\n",
    "    'val_accuracy': acc,\n",
    "    'val_mAP': mAP,\n",
    "    'history': history,\n",
    "    'val_imgs': val_imgs,\n",
    "    'val_labels': val_labels,\n",
    "    'val_preds': val_preds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ce5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_densenet121.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, res in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  Training Time: {res['training_time_sec']:.2f} seconds\")\n",
    "    print(f\"  Validation Accuracy: {res['val_accuracy']:.4f}\")\n",
    "    print(f\"  Validation mAP: {res['val_mAP']:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISB46703",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
