{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: connect to drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwjIybKZ7_qW",
        "outputId": "40a956ad-bdd1-4aa6-afe7-cc60e4e4862c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: go to Colab Notebooks directory inside drive\n",
        "\n",
        "%cd drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKY-f7rz8L2J",
        "outputId": "5604960d-e1ba-4366-bd15-49d08445dbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks'\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuEfqmWR9hRE",
        "outputId": "43634f99-c5d7-432a-b243-484e46bebe72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "metadata": {
        "id": "5IEPylR69YEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.get_strategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJQ9_nvnFcSb",
        "outputId": "5dbbf36f-7a21-4204-cc44-4decd922c49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = './dataset/train'\n",
        "valid_path = './dataset/val'\n",
        "test_path = './dataset/test'\n",
        "\n",
        "breeds = [\n",
        "    \"Holstein_cow\", \"Jersey_cow\", \"Angus_cow\", \"Brahman_cow\", \"Hereford_cow\",\n",
        "    \"Simmental_cow\", \"Limousin_cow\", \"Guernsey_cow\", \"Charolais_cow\", \"Ayrshire_cow\"\n",
        "]\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
        "                .flow_from_directory(directory=train_path, target_size=(224,224), classes=breeds, batch_size = 10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
        "                .flow_from_directory(directory=valid_path, target_size=(224,224), classes=breeds, batch_size = 10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
        "                .flow_from_directory(directory=test_path, target_size=(224,224), classes=breeds, batch_size = 10, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5up0Yoio9oXw",
        "outputId": "d696d9db-a730-44b4-d053-85ad0805bb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2802 images belonging to 10 classes.\n",
            "Found 1069 images belonging to 10 classes.\n",
            "Found 1083 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert train_batches.n >= 1000\n",
        "assert valid_batches.n >= 300\n",
        "assert test_batches.n >= 150\n",
        "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 10\n",
        "assert train_batches.batch_size == valid_batches.batch_size == test_batches.batch_size == 10\n",
        "assert train_batches.class_indices == valid_batches.class_indices == test_batches.class_indices"
      ],
      "metadata": {
        "id": "8wC4mB88-M7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs , labels = next(train_batches)\n",
        "print(\"Shape of the image batch: \", imgs.shape)\n",
        "print(\"Shape of the label batch: \", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxD62fGE-R_R",
        "outputId": "0bbeba90-cfba-4f73-ced6-ff077b422208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the image batch:  (10, 224, 224, 3)\n",
            "Shape of the label batch:  (10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 10, figsize = (20, 20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr,axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plotImages(imgs)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orh6-VSx-VAu",
        "outputId": "9770ae74-21fb-427a-9820-3ac41a8f2992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32,kernel_size=(3,3),activation='relu', padding='same',input_shape=(224,224,3)),\n",
        "        MaxPool2D(pool_size=(2,2),strides=2),\n",
        "        Conv2D(filters=64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "        MaxPool2D(pool_size=(2,2), strides=2),\n",
        "        Flatten(),\n",
        "        Dense(units=10, activation='softmax'),\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Z_rbHs-WnA",
        "outputId": "b1a2048f-a498-4629-bd7c-c1a1af0ccdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "_RqhscNr-be8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121, MobileNetV3Large\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "1oJXvBen-eCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(base_model_class, input_shape, num_classes):\n",
        "    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "PU5tXMM_-hCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to calculate mAP\n",
        "def mean_average_precision(y_true, y_pred):\n",
        "    # y_true and y_pred should be numpy arrays\n",
        "    # This is a simple implementation for multiclass, multi-label\n",
        "    import sklearn.metrics\n",
        "    return sklearn.metrics.average_precision_score(y_true, y_pred, average='macro')\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(breeds)\n",
        "epochs = 50\n",
        "results = {}"
      ],
      "metadata": {
        "id": "K4jVxGYW-lRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training MobileNetV3Large...\")\n",
        "mobilenetv3_model = build_model(MobileNetV3Large, input_shape, num_classes)\n",
        "start_time = time.time()\n",
        "history = mobilenetv3_model.fit(\n",
        "    train_batches,\n",
        "    validation_data=valid_batches,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        ")\n",
        "training_time = time.time() - start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2n2X93Q-rfa",
        "outputId": "757610e4-3bb7-4782-88a8-10b17453c710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MobileNetV3Large...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 - 140s - 497ms/step - accuracy: 0.5485 - loss: 1.3805 - val_accuracy: 0.1824 - val_loss: 10.0715\n",
            "Epoch 2/50\n",
            "281/281 - 19s - 67ms/step - accuracy: 0.7659 - loss: 0.7345 - val_accuracy: 0.2254 - val_loss: 8.7715\n",
            "Epoch 3/50\n",
            "281/281 - 19s - 68ms/step - accuracy: 0.8430 - loss: 0.5015 - val_accuracy: 0.2208 - val_loss: 8.6997\n",
            "Epoch 4/50\n",
            "281/281 - 19s - 69ms/step - accuracy: 0.8694 - loss: 0.4022 - val_accuracy: 0.1684 - val_loss: 12.1758\n",
            "Epoch 5/50\n",
            "281/281 - 18s - 64ms/step - accuracy: 0.9004 - loss: 0.3296 - val_accuracy: 0.1759 - val_loss: nan\n",
            "Epoch 6/50\n",
            "281/281 - 20s - 71ms/step - accuracy: 0.9115 - loss: 0.2664 - val_accuracy: 0.4022 - val_loss: 5.8598\n",
            "Epoch 7/50\n",
            "281/281 - 20s - 70ms/step - accuracy: 0.9236 - loss: 0.2428 - val_accuracy: 0.5023 - val_loss: 3.6299\n",
            "Epoch 8/50\n",
            "281/281 - 19s - 68ms/step - accuracy: 0.9286 - loss: 0.2263 - val_accuracy: 0.4668 - val_loss: 3.8531\n",
            "Epoch 9/50\n",
            "281/281 - 18s - 65ms/step - accuracy: 0.9383 - loss: 0.1891 - val_accuracy: 0.3471 - val_loss: 7.5613\n",
            "Epoch 10/50\n",
            "281/281 - 19s - 67ms/step - accuracy: 0.9218 - loss: 0.2416 - val_accuracy: 0.4378 - val_loss: 5.1202\n",
            "Epoch 11/50\n",
            "281/281 - 19s - 69ms/step - accuracy: 0.9458 - loss: 0.1558 - val_accuracy: 0.3807 - val_loss: nan\n",
            "Epoch 12/50\n",
            "281/281 - 18s - 65ms/step - accuracy: 0.9379 - loss: 0.1978 - val_accuracy: 0.1918 - val_loss: 11.8652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_imgs, val_labels = next(valid_batches)\n",
        "val_preds = mobilenetv3_model.predict(val_imgs)\n",
        "acc = np.mean(np.argmax(val_preds, axis=1) == np.argmax(val_labels, axis=1))\n",
        "mAP = mean_average_precision(val_labels, val_preds)\n",
        "results['MobileNetV3Large'] = {\n",
        "    'training_time_sec': training_time,\n",
        "    'val_accuracy': acc,\n",
        "    'val_mAP': mAP,\n",
        "    'history': history,\n",
        "    'val_imgs': val_imgs,\n",
        "    'val_labels': val_labels,\n",
        "    'val_preds': val_preds\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP4yfjlw-wsF",
        "outputId": "ac13aad3-c87b-466b-bb45-325894f1bbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79553f9e8540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('mobilenetv3_results.pkl', 'wb') as file:\n",
        "    pickle.dump(results, file)"
      ],
      "metadata": {
        "id": "DYGWzuM--5Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, res in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Training Time: {res['training_time_sec']:.2f} seconds\")\n",
        "    print(f\"  Validation Accuracy: {res['val_accuracy']:.4f}\")\n",
        "    print(f\"  Validation mAP: {res['val_mAP']:.4f}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MnnZ0ci-7r2",
        "outputId": "e7841acf-8390-4d9c-9d62-fbe41544889b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MobileNetV3Large\n",
            "  Training Time: 348.28 seconds\n",
            "  Validation Accuracy: 0.6000\n",
            "  Validation mAP: 0.4500\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7c7d0ec"
      },
      "source": [
        "strategy = tf.distribute.get_strategy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}